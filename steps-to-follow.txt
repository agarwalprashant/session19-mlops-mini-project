- create a project repo using cookiecutter
cookiecutter -c v1 http://github.com/drivendata/cookiecutter-data-science

delete files -› models to model

create venv -> python -m venv myenv -› activate

- git init

create git repo

add remote

push repo to Gi 1b

- Setup mlflow on Dagshub

https://dagshub.com/agarwalprashant/session19-mlops-mini-project.mlflow


import dagshub
dagshub.init(repo_owner='agarwalprashant', repo_name='session19-mlops-mini-project', mlflow=True)

import mlflow
with mlflow.start_run():
  mlflow.log_param('parameter name', 'value')
  mlflow.log_metric('metric name', 1)


- run dagshub_setup. py

- Write Exp 1 -› Baseline experiment (https://raw.githubusercontent.com/campusx-official/jupyter-
masterclass/main/tweet_emotions.csv)

- add miruns to •gitignore

- commit & push

- Write Exp 2

- commit & push Host


- dvc init

- add dvc remote (local)
dvc remote add -d myremote (local)

- Create a DVC pipeline
data_ingestion -> data preprocessing -> feature engineering -> model building -> model evaluation

- dvc.yaml + params.yaml

- run dvc repro

- dvc status/git status

- git commit

- dvc push and git push

- remove local remote
dvc remote list
dvc remote remove myremote

------------------------------------------------------
session20 mlops campusx model serving video
create s3 bucket
create IAM user
pip install 'dvc[s3]' awscli
dvc remote add -d myremote s3://mlops-session20-bucket-1234567890/data